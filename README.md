# Random Reading
This is a repo to record my random reading history, i will also write some sparks about the paper randomly


### o1 / DeepSeek-R1

- [s1: Simple test-time scaling](https://arxiv.org/pdf/2501.19393.pdf) the potential of SFT data

- [KIMI K1.5: SCALING REINFORCEMENT LEARNING WITH LLMS](https://arxiv.org/pdf/2501.12599v1)

- https://github.com/Open-Reasoner-Zero/Open-Reasoner-Zero/blob/main/ORZ_paper.pdf

- https://hkust-nlp.notion.site/simplerl-reason

- https://efficient-unicorn-451.notion.site/Online-DPO-R1-Unlocking-Effective-Reasoning-Without-the-PPO-Overhead-1908b9a70e7b80c3bc83f4cf04b2f175

- [Demystifying Long Chain-of-Thought Reasoning in LLMs](https://arxiv.org/abs/2502.03373.pdf)

- [DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning](https://arxiv.org/pdf/2501.12948)


### Abstarct / Program Reasoning

- [Conceptual and Unbiased Reasoning in Language Models](https://arxiv.org/pdf/2404.00205)

- [ReasonFlux: Hierarchical LLM Reasoning via Scaling Thought Templates](https://arxiv.org/pdf/2502.06772.pdf)

### Math

- [rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking](https://arxiv.org/abs/2501.04519.pdf)

- [Step-level Value Preference Optimization for Mathematical Reasoning]

- [STaR: Self-Taught Reasoner Bootstrapping Reasoning With Reasoning](https://arxiv.org/pdf/2203.14465.pdf)

### Reward Model

- [R-PRM: Reasoning-Driven Process Reward Modeling](https://arxiv.org/abs/2503.21295.pdf)

- [Self-rewarding correction for mathematical reasoning](https://arxiv.org/pdf/2502.19613.pdf)

- [AdaptiveStep: Automatically Dividing Reasoning Step through Model Confidence](https://arxiv.org/abs/2502.13943.pdf)

- [Process-based Self-Rewarding Language Models](https://arxiv.org/pdf/2503.03746.pdf)

- [AgentRM: Enhancing Agent Generalization with Reward Modeling](https://arxiv.org/pdf/2502.18407.pdf)

- [Rule Based Rewards for Language Model Safety](https://arxiv.org/pdf/2411.01111.pdf)

- [Self-Generated Critiques Boost Reward Modeling for Language Models](https://arxiv.org/pdf/2411.16646.pdf)

- [Critique Fine-Tuning: Learning to Critique is More Effective than Learning to Imitate](https://arxiv.org/abs/2501.17703.pdf)

- [Generative Reward Models](https://arxiv.org/abs/2410.12832.pdf)

- [SELF-EVOLVED REWARD LEARNING FOR LLMS](https://arxiv.org/pdf/2411.00418)

- [Self-rewarding Language Models]

### Physics of Language Models

- [ICML Tut: Physics of Language Models](https://www.youtube.com/watch?v=kf_eGgVtOcs)

    - [Physics of Language Models: Part 2.1, Grade-School Math and the Hidden Reasoning Process](https://arxiv.org/pdf/2407.20311)

    - [Physics of Language Models: Part 2.2, How to Learn From Mistakes on Grade-School Math Problems](https://arxiv.org/pdf/2408.16293) `dependency structure` may related to metabench, used in thesis

    - [Physics of Language Models: Part 3.1,Knowledge Storage and Extraction](https://arxiv.org/pdf/2309.14316.pdf)

    - [Physics of Language Models: Part 3.2, Knowledge Manipulation](https://arxiv.org/pdf/2309.14402.pdf)

### Chain-of-X / Prompting Methods

- [Chain-of-code: Reasoning with a Language Model-Augmented Code Emulator]

- [SWIFTSAGE: A Generative Agent with Fast and Slow Thinking for Complex Interactive Tasks] :fire::fire::fire: Important

- [Answering Questions by Meta-Reasoning over Multiple Chains of Thought](https://aclanthology.org/2023.emnlp-main.364/)

- [Guiding Large Language Models via Directional Stimulus Prompting](https://arxiv.org/abs/2302.11520.pdf) [code](https://github.com/Leezekun/Directional-Stimulus-Prompting)

- [Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models](https://arxiv.org/pdf/2406.04271.pdf)


### Language Agents

- [Agent AI: Surveying the Horizons of Multimodal Interaction](https://arxiv.org/pdf/2401.03568.pdf) :fire::fire::fire::fire:

- [AGENT WORKFLOW MEMORY](https://arxiv.org/pdf/2409.07429.pdf)

- [An Interactive Agent Foundation Model](https://arxiv.org/abs/2402.05929.pdf)

- [Reinforcement Learning for Long-Horizon Interactive LLM Agents](https://arxiv.org/abs/2502.01600.pdf)

- [Language Agent Tree Search Unifies Reasoning, Acting, and Planning in Language Models](https://arxiv.org/pdf/2310.04406.pdf) `knowledge and reasoning` `code`

- [Trial and Error: Exploration-Based Trajectory Optimization of LLM Agents](https://arxiv.org/pdf/2403.02502) [`code`](https://github.com/Yifan-Song793/ETO)

- [GPTSwarm: Language Agents as Optimizable Graphs](https://arxiv.org/pdf/2402.16823#page=2.48.pdf)

- [ReAct Meets ActRe: When Language Agents Enjoy Training Data Autonomy](https://arxiv.org/pdf/2403.14589.pdf)

- [Agent-Pro: Learning to Evolve via Policy-Level Reflection and Optimization](https://arxiv.org/pdf/2402.17574.pdf)

- [Mixture-of-Agents Enhances Large Language Model Capabilities](https://arxiv.org/abs/2406.04692.pdf)

- [Cognitive Architectures for Language Agents](https://arxiv.org/abs/2309.02427) very important work in language agents

- [CogAgent: A Visual Language Model for GUI Agents](https://arxiv.org/pdf/2312.08914.pdf) Tsinghua, multi-modal agent

- [Webarena: A REALISTIC WEB ENVIRONMENT FOR BUILDING AUTONOMOUS AGENTS](https://arxiv.org/abs/2307.13854)

- [AndroidEnv: A Reinforcement Learning Platform for Android](https://arxiv.org/pdf/2105.13231.pdf)

- [VirtualHome: Simulating Household Activities via Programs](https://arxiv.org/pdf/1806.07011.pdf)

- [A Collaborative Multi-agent Reinforcement Learning Framework for Dialog Action Decomposition]

- [AGENTBOARD: AN ANALYTICAL EVALUATION BOARD OF MULTI-TURN LLM AGENTS](https://arxiv.org/pdf/2401.13178.pdf) text-based agents

- [MINT: EVALUATING LLMS IN MULTI-TURN INTERACTION WITH TOOLS AND LANGUAGE FEEDBACK](https://arxiv.org/pdf/2309.10691.pdf) a multi-turn evaluation method, or a approach to solve reasoning problems, like SwiftSage

- Other Important / Useful Resources

    - [Formulating and Evaluating Language Agents](https://www.youtube.com/watch?v=qmGu9okiICU) `Shunyu Youtube`

    - [Language Agents in the Digital World: Opportunities and Risks](https://princeton-nlp.github.io/language-agent-impact/) `Shunyu Blog`


#### Embodied AI

- [SCIENCEWORLD: Is your Agent Smarter than a 5th Grader?] `Interactive Env`

- [ALFWorld: Aligning Text and Embodied Environments for Interactive Learning]

- [Virtualhome: Simulating household activities via programs]

- [Towards Efficient LLM Grounding for Embodied Multi-Agent Collaboration]


### Tool Learning
 
- [Tool-Augmented Reward modeling](https://arxiv.org/abs/2310.01045.pdf) teach reward model to use tools

- [ViperGPT: Visual Inference via Python Execution for Reasoning](https://arxiv.org/abs/2303.08128) `CV`

- [Confucius: Iterative Tool Learning from Introspection Feedback by Easy-to-Difficult Curriculum](https://arxiv.org/abs/2308.14034) `AAAI 2024`

- [API-Bank: A Comprehensive Benchmark for Tool-Augmented LLMs](https://aclanthology.org/2023.emnlp-main.187.pdf) :fire::fire::fire: important work, also for dialogues

- [GAIA: A Benchmark for General AI Assistants](https://arxiv.org/pdf/2311.12983.pdf)

#### Self-improvement / Data Synthesis

- [Mitigating Tail Narrowing in LLM Self-Improvement via Socratic-Guided Sampling](https://arxiv.org/pdf/2411.00750)

#### Self-critique / Self-rewarding

- [Training Language Models to Self-Correct via Reinforcement Learning](https://arxiv.org/pdf/2409.12917.pdf)

- [META-REWARDING LANGUAGE MODELS: Self-Improving Alignment with LLM-as-a-Meta-Judge](https://arxiv.org/pdf/2407.19594)

- [Internal Consistency and Self-Feedback in Large Language Models: A Survey](https://arxiv.org/pdf/2407.14507)

- [LLMs cannot find reasoning errors, but can correct them given the error location](https://aclanthology.org/2024.findings-acl.826.pdf)

- [Learning From Correctness Without Prompting Makes
LLM Efficient Reasoner](https://arxiv.org/pdf/2403.19094.pdf)


#### Cognitive Tool

- [Learning to Trust Your Feelings: Leveraging Self-awareness in LLMs for Hallucination Mitigation](https://aclanthology.org/2024.knowledgenlp-1.4.pdf)

- [StrategyLLM: Large Language Models as Strategy Generators, Executors, Optimizers, and Evaluators for Problem Solving](https://arxiv.org/pdf/2311.08803.pdf)

- [FACTSCORE: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation](https://aclanthology.org/2023.emnlp-main.741.pdf)

### Personalization

- [FSPO: Few-Shot Preference Optimization of Synthetic Preference Data in LLMs Elicits Effective Personalization to Real Users](https://www.arxiv.org/pdf/2502.19312)

- []

### AI for Education

- [TRAINING LLM-BASED TUTORS TO IMPROVE STUDENT LEARNING OUTCOMES IN DIALOGUES](https://arxiv.org/pdf/2503.06424.pdf)

- [SocraticLM: Exploring Socratic Personalized Teaching with Large Language Models](https://openreview.net/pdf?id=qkoZgJhxsA)

### Role-playing

- [In-Context Impersonation Reveals Large Language Modelsâ€™ Strengths and Biases]  `the effects of persona`

- [Scaling Synthetic Data Creation with 1,000,000,000 Personas](https://arxiv.org/abs/2406.20094) :fire::fire:

- [Harnessing Multi-Role Capabilities of Large Language Models for Open-Domain Question Answering](https://arxiv.org/pdf/2403.05217.pdf)


### Alignment / Reinforcement Learning

- [RL-GPT: Integrating Reinforcement Learning and Code-as-policy] `code`

- [Controllable Preference Optimization: Toward Controllable Multi-Objective Alignment](https://arxiv.org/pdf/2402.19085.pdf)

- [Alignment for Honesty](https://arxiv.org/pdf/2312.07000.pdf)

- [SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training]

### Others

- [Meta-Reasoning: Semantics-Symbol Deconstruction for Large Language Models](https://arxiv.org/abs/2306.17820) writing is so good

### Confidence/Uncertainty Alignment

- [LM-Polygraph: Uncertainty Estimation for Language Models](https://aclanthology.org/2023.emnlp-demo.41.pdf) 

### Explanation

- [Towards a Mechanistic Interpretation of Multi-Step Reasoning Capabilities of Language Models](https://arxiv.org/pdf/2310.14491.pdf)

- [What Do Language Models Learn in Context? The Structured Task Hypothesis](https://arxiv.org/pdf/2406.04216.pdf)


### Model Level -- from larger model to small model

- [Personalised Distillation: Empowering Open-Sourced LLMs with Adaptive Learning for Code Generation](https://arxiv.org/pdf/2310.18628.pdf)


### Knowledge Editting & Interpretability

- [Locating and Editing Factual Associations in GPT](https://arxiv.org/abs/2202.05262.pdf)


### Knowledge Conflict

- [Competition of Mechanisms: Tracing How Language Models Handle Facts and Counterfactuals](https://arxiv.org/pdf/2402.11655.pdf)

- [Adaptive Chameleon or Stubborn Sloth: REVEALING THE BEHAVIOR OF LARGE LANGUAGE MODELS IN KNOWLEDGE CONFLICTS](https://arxiv.org/abs/2305.13300.pdf)



### Text-to-Image / Multi-modal

- [IP-Adapter: Text Compatible Image Prompt Adapter for Text-to-Image Diffusion Models](https://arxiv.org/pdf/2308.06721)


### Other Useful Resources

- [Make Your Own Research Impact in AI](https://github.com/okhat/blog/blob/main/2024.09.impact.md)